ID3决策树
===
	1. 算法
	   1. 计算对给定样本分类所需的信息熵
	   2. 计算每个特征的信息熵
信息熵的计算
---
	1. 不确定性函数I称为事件的信息量，是事件U发生概率p的单调递减函数，两个独立事件
	   所产生的不确定性应等于各自不确定性之和
决策树
===
	1. 将决策树设计为三类节点：根节点、叶子节点、内部节点

决策树的算法框架
---
	1. 决策树主函数
	   1. 本质是递归函数，按照某种规则生长出决策树的各个分支节点，并根据终止条件结束算法
	   2. 功能
          1. 输入需要分类的数据集和类别标签
	      2. 根据某种分类规则得到最优的划分特征，并创建特征的划分节点---计算最优特征子函数
	      3. 按照该特征的每个取值划分数据集为若干部分---划分数据集子函数
	      4. 根据划分子函数的计算结果构建出新的节点，作为树生长的新分支
	      5. 检验是否符合递归的终止条件
	      6. 将划分的新节点包含的数据集和类别标签作为输入，递归执行上述步骤 
    2. 计算最优特征子函数
	3. 划分数据集函数
	4. 分类器

信息熵测度
---
	1. 标称数据离散化，如何选出特征集中无序度最大的那列特征作为划分节点
	2. 熵：任何一种能量在空间分布的均匀程度
    3. **在决策树中,不仅可以度量类别的不确定性,也可以度量包含不同特性的数据样本
       与类别的不确定性.即某个列向量的信息熵越大,说明该向量的不确定性程度越大,优
       先考率从该特征向量划分**
       
信息熵计算
---
    1. 使用信息熵来度量类别标签对样本整体的不确定性

C4.5算法
---
    1. 在节点的划分标准上，C4.5使用信息增益率来替代信息增益，克服了信息增益选择特征时偏向于特征值个数较多的不足

Scikit-Learn与回归树
===

回归算法流程`
---

最小剩余方差法

